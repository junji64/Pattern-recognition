{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선형판별분석법(LDA)\n",
    "\n",
    "- **PCA(주성분 분석법: Principal Component Analysis)**은 데이타의 **최적 표현**의 견지에서 데이타 차원을 축소하는 방법\n",
    "- **LDA(선형판별 분석법: Linear Discriminent Analysis)**은 데이타의 **최적 분류**의 견지에서 데이타 차원을 축소하는 방법\n",
    "  - (목적) 가능한 클래스 간의 분별정보를 최대한 유지시키면서 차원을 축소\n",
    "  - D-차원 표본 데이타 집합 $X=\\{x^{(1},x^{(2},\\cdots,x^{(N}\\}$ 가 주어진 경우, $\\omega_1$클래스에 속하는 것이 $N_1$개이고, $\\omega_2$클래스에 속하는 것이 $N_2$개 일  때, $x^{(i}$를 임의의 선을 따라서 사영하여 스칼라 $y$를 얻고자 한다.\n",
    "  $$ y = W^Tx $$\n",
    "  - 가능한 모든 선들 중에서 이러한 $\\omega_1$ 과 $\\omega_2$의 스칼라 값들의 분리를 최대화 하는 것을 선택한다.( 예: 2차원의 경우 다음과 같다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bc47479748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "X = [[5,5.2,6,6.1,6.2,6.4,7], [3.5,3.7,4.5,3,4,4.4,4.1]]\n",
    "plt.plot(X[0], X[1], 'ro')\n",
    "Y = [[6,6.2,7,7.1,7.2,7.4,8], [5.5,5.7,6.5,5,6,6.4,6.1]]\n",
    "plt.plot(Y[0], Y[1], 'bo')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형판별분석법(LDA)은 특징 공간 상에서 클래스분리를 최대화 하는 주축으로 사상시켜 선형 부공간으로 차원을 축소하는 방법이다.\n",
    "- 선형판별분석법(LDA)에서는 클래스간 분산(between-class scatter)과 클래스내 분산(within-class scatter)의 비율을 최대화하는 방식으로 데이타에 대한 특징벡터의 차원을 축소한다.\n",
    "$$ \\text{클래스간 분산(between-class Scatter)} \\over \\text{클래스내 분산(within-class Scatter) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2진 분류에 적용된 LDA\n",
    "어느 사영을 취하는 것이 좋을 것인가? ==> 좋은 사영을 찾기 위해서는 사영들 간의 분리정도를 측정할 수 있어야 한다.\n",
    "\n",
    "선형변환에의 한 사영\n",
    "$$ y = w^Tx $$\n",
    "여기에서 w: Dx1, x: Dx1\n",
    "\n",
    "평균을 기중 척도로 하면, 각 클래스들의 x와 y 에서의 평균백터는 다음과 같다.\n",
    "$$ \\mu_i = {1 \\over N_i}\\sum_{x\\in\\omega_i} x $$\n",
    "$$ \\tilde{\\mu_i} = {1 \\over N_i}\\sum_{y\\in\\omega_i} y = {1 \\over N_i}\\sum_{x\\in\\omega_i} w^T x = w^T  \\mu_i $$\n",
    "이 때 사영된 데이터들의 중심(평균) 간의 거리를 목적함수로 선택하면 \n",
    "$$ J(W) = \\bracevert \\tilde{\\mu_1} - \\tilde{\\mu_2}\\bracevert = \\bracevert w^T ( \\mu_1 -\\mu_2  )\\bracevert $$\n",
    "하지만, 이렇게 평균 만을 고려하면, 클래스 안에서의 표준편차가 고려되지 않으므로 좋은 척도가 아니다.\n",
    "\n",
    "Fisher 에 의해서 제안된 방법은 클래스내(within-class)의 스캐터로 정규화한 평균들간의 차이로 표현된 함수를 최대화 시키는 것이다.\n",
    "각 클래스들에 대하여 스캐터는 다음과 같이 주어지며\n",
    "\n",
    "$$ \\tilde {S_i} = \\sum_{y\\in\\omega_i} (y-\\tilde{\\mu_i})^2= \\sum_{y\\in\\omega_i} (y-\\tilde{\\mu_i})(y-\\tilde{\\mu_i})^T$$\n",
    "\n",
    "사영 표본들의 클래스내 분산(within-class scatter) \n",
    "$$ S_B = (\\tilde {S_1} + \\tilde {S_2} ) $$\n",
    "\n",
    "따라서, Ficher 의 선형판별은 다음의 목적함수를 최대화 하는 선형함수 $w^Tx$에 해당한다.\n",
    "$$ J(w) = { \\bracevert \\tilde{\\mu_1} - \\tilde{\\mu_2}\\bracevert ^2 \\over \\tilde {S_1} + \\tilde {S_2} }$$\n",
    "따라서, Fisher의 선형판펼식은 동일한 클래스의 표본들은 인접하게 사영이 취해지고, 동시에 클래스 간의 사영은 중심들이 가능한 멀리 떨어지게 하는 변환 행렬($w$)를 찾아내는 것이다.\n",
    "\n",
    "어떻게 변환행렬($w$) 에 대한 함수로 표현되는 위의 목적함수 $J(w)$를 최대화 하는 변환행렬 $w$를 찾을 것인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적의 사영 $\\bf{w}$를 구하기 위해서는 $J(\\bf{w})$를 $\\bf{w}$에 대한 함수로 표현해야 한다. \n",
    "다차원 특징공간에서 스캐터행렬은 사영상에서 분산과 동일한 형태\n",
    "$$ \\bf{S_i} = \\sum_{x\\in\\omega_i} (x-\\mu_i)(x-\\mu_i)^T $$\n",
    "따라서, 클래스내 스캐터행렬 $$ S_w = S_1 + S_2 $$\n",
    "사영된 $\\bf{y}$의 스캐터를 특징백터 $\\bf{x}$의 스캐터 행렬의 함수로 다음과 같이 표현이 된다.\n",
    "\n",
    "\\begin{align*}\n",
    "\\bf{\\tilde S_i} &= \\sum_{y\\in\\omega_i} \\bf{(y-\\tilde{\\mu_i})(y-\\tilde{\\mu_i})^T} \\\\\n",
    "                  &= \\sum_{y\\in\\omega_i} \\bf{(w^Tx-w^T\\mu_i)(w^Tx-w^T\\mu_i)^T}\\\\\n",
    "                  & = \\sum_{y\\in\\omega_i} \\bf{w^T(x-\\mu_i)(x-\\mu_i)^T}w\\\\\n",
    "                  & =  \\bf{w^T S_i w} \\\\\n",
    "\\end{align*}\n",
    "따라서\n",
    "$$ \\bf { \\tilde {S}_w = \\tilde{S}_1 + \\tilde{S}_2 = w^T S_w w}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지로 사영된 평균들 간의 차이(~분산)를 원래의 특징공간에서의 평균들 간의 차이로 다음과 같이 동일한 표현될 수 있다.\n",
    "\n",
    "\\begin{align*}\n",
    "(\\bf{\\tilde\\mu_1 - \\tilde\\mu_2})^2  &= (\\bf{w^T \\mu_1 - w^T \\mu_2})^2 \\\\\n",
    "&= \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
